"""
wsa_train.py

Main training script for WSA (Wang-Sheeley-Arge) map prediction.

This script orchestrates the complete training pipeline:
  - Loads configuration from wsa_config.yaml
  - Creates train/val/test datasets with specified CR lists
  - Loads pre-trained Surya encoder and attaches WSA decoder head
  - Sets up PyTorch Lightning training with logging and checkpointing
  - Trains the model on WSA map prediction task

Usage:
    python wsa_train.py
    
    Optional CLI arguments:
    python wsa_train.py --config ./configs/wsa_config.yaml --cuda-device 0
"""

import os
import sys
import argparse
from datetime import datetime
from pathlib import Path

import torch
import yaml
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning.loggers import CSVLogger, WandbLogger
from torch.utils.data import DataLoader

# Add paths for imports
sys.path.append("../")
sys.path.append("../Surya")

from surya.utils.data import build_scalers
from wsa_surya_training.datasets.wsa_dataset import WSAImageDataset
from wsa_surya_training.metrics.wsa_metrics import WSAMetrics
from wsa_surya_training.models.wsa_model_head import WSAModel
from wsa_surya_training.lightning_modules.wsa_lightning_module import WSALightningModule


# ============================================================================
# Configuration & Setup
# ============================================================================

def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Train WSA map prediction model"
    )
    parser.add_argument(
        "--config",
        type=str,
        default="./configs/wsa_config.yaml",
        help="Path to configuration file"
    )
    parser.add_argument(
        "--cuda-device",
        type=int,
        default=0,
        help="CUDA device ID to use"
    )
    parser.add_argument(
        "--unfreeze-encoder",
        action="store_true",
        help="Unfreeze encoder for fine-tuning (default: frozen)"
    )
    return parser.parse_args()


def setup_environment(cuda_device: int):
    """Configure environment variables for training."""
    os.environ["CUDA_VISIBLE_DEVICES"] = str(cuda_device)
    
    # Configure W&B directories
    os.environ["WANDB_DIR"] = "./wandb/wandb_logs"
    os.environ["WANDB_CACHE_DIR"] = "./wandb/wandb_cache"
    os.environ["WANDB_CONFIG_DIR"] = "./wandb/wandb_config"
    os.environ["TMPDIR"] = "./wandb/wandb_tmp"
    
    # Create directories if they don't exist
    for dir_path in [
        os.environ["WANDB_DIR"],
        os.environ["WANDB_CACHE_DIR"],
        os.environ["WANDB_CONFIG_DIR"],
        os.environ["TMPDIR"],
    ]:
        os.makedirs(dir_path, exist_ok=True)
    
    # Set precision and reproducibility
    torch.set_float32_matmul_precision('medium')
    pl.seed_everything(42, workers=True)
    
    print(f"‚úÖ Environment configured (CUDA device: {cuda_device})")


def load_config(config_path: str) -> dict:
    """Load and parse YAML configuration file."""
    print(f"üìã Loading configuration from {config_path}...")
    
    try:
        with open(config_path, "r") as f:
            config = yaml.safe_load(f)
        
        # Load scalers configuration
        scalers_path = config["data"]["scalers_path"]
        with open(scalers_path, "r") as f:
            config["data"]["scalers_path"] = yaml.safe_load(f)
        
        print("‚úÖ Configuration loaded successfully!")
        return config
    
    except FileNotFoundError as e:
        print(f"‚ùå Error: {e}")
        print(f"Make sure config file exists at {config_path}")
        raise


# ============================================================================
# Dataset Creation
# ============================================================================

def create_datasets(config: dict, scalers: dict) -> tuple:
    """Create train, val, and test datasets from configuration."""
    print("\nüìä Creating datasets...")
    
    # Common parameters
    dataset_kwargs = {
        "surya_index_path": config["data"]["surya_index_path"],
        "wsa_map_dir": config["data"]["wsa_map_dir"],
        "wsa_params_path": config["data"]["wsa_params_path"],
        "scalers": scalers,
        "channels": config["data"]["channels"],
        "normalize_wsa": config.get("normalize_wsa_maps", True),
        "tolerance_days": config["data"]["cr_tolerance_days"],
        "s3_use_simplecache": config["data"]["s3_use_simplecache"],
        "s3_cache_dir": config["data"]["s3_cache_dir"],
    }
    
    # Create train dataset
    train_dataset = WSAImageDataset(
        cr_list=config["data"]["train_crs"],
        phase="train",
        **dataset_kwargs
    )
    
    # Create validation dataset
    val_dataset = WSAImageDataset(
        cr_list=config["data"]["val_crs"],
        phase="val",
        **dataset_kwargs
    )
    
    # Create test dataset
    test_dataset = WSAImageDataset(
        cr_list=config["data"]["test_crs"],
        phase="test",
        **dataset_kwargs
    )
    
    print(f"‚úÖ Datasets created:")
    print(f"   - Train: {len(train_dataset)} samples")
    print(f"   - Val:   {len(val_dataset)} samples")
    print(f"   - Test:  {len(test_dataset)} samples")
    
    return train_dataset, val_dataset, test_dataset


def create_dataloaders(
    train_dataset,
    val_dataset,
    test_dataset,
    batch_size: int,
    num_workers: int = 4
) -> tuple:
    """Create PyTorch DataLoaders from datasets."""
    print("\nüîÑ Creating dataloaders...")
    
    loader_kwargs = {
        "batch_size": batch_size,
        "num_workers": num_workers,
        "multiprocessing_context": "spawn",
        "persistent_workers": True,
        "pin_memory": True,
    }
    
    train_loader = DataLoader(
        dataset=train_dataset,
        shuffle=True,
        **loader_kwargs
    )
    
    val_loader = DataLoader(
        dataset=val_dataset,
        shuffle=False,
        **loader_kwargs
    )
    
    test_loader = DataLoader(
        dataset=test_dataset,
        shuffle=False,
        **loader_kwargs
    )
    
    print(f"‚úÖ Dataloaders created (batch_size: {batch_size})")
    
    return train_loader, val_loader, test_loader


# ============================================================================
# Model Setup
# ============================================================================

def load_surya_encoder(checkpoint_path: str, device: str = "cuda"):
    """Load pre-trained Surya encoder from checkpoint."""
    print(f"\nüß† Loading Surya encoder from {checkpoint_path}...")
    
    try:
        # Import Surya model (adjust based on actual Surya API)
        # from surya.models.helio_spectformer import HelioSpectFormer
        from workshop_infrastructure.models.finetune_models import HelioSpectformer2D
        
        ###############
        # Load checkpoint
        
        # Initialize encoder
        # encoder = HelioSpectFormer(
        #     img_size=4096,
        #     patch_size=16,
        #     in_chans=1,  # Single AIA 193 channel
        #     embed_dim=1280,
        #     depth=10,
        #     num_heads=16,
        #     mlp_ratio=4.0,
        #     window_size=2,
        #     time_embedding={'type': 'linear', 'time_dim':1},
        #     n_spectral_blocks =  1,
        #     drop_rate =  0.1,
        #     dp_rank=1,
        # )

        model = HelioSpectformer2D(
            img_size=4096,
            patch_size=16,
            in_chans=13,
            embed_dim=1280,
            time_embedding={'type': 'linear', 'time_dim': 1},
            depth=10,
            num_heads=16,
            mlp_ratio=4.0,
            drop_rate=0.1,
            window_size=2,
            dp_rank=1,
            n_spectral_blocks=1,
            config={}  # Pass an empty dictionary if no specific config is 
        )
        
        # # Load weights (adjust key mapping if needed)
        # if "model" in checkpoint:
        #     encoder.load_state_dict(checkpoint["model"], strict=False)
        # else:
        #     encoder.load_state_dict(checkpoint, strict=False)

        model_state = model.state_dict()
        # checkpoint_state = torch.load(config["pretrained_path"], weights_only=True, map_location="cpu")
        checkpoint_state = torch.load(checkpoint_path, weights_only=True,map_location=device)
        filtered_checkpoint_state = {
            k: v
            for k, v in checkpoint_state.items()
            if k in model_state and v.shape == model_state[k].shape
        }

        # 2. Load the filtered weights
        model_state.update(filtered_checkpoint_state)
        model.load_state_dict(model_state, strict=True)
        
        encoder = model.to(device)
        print("‚úÖ Surya encoder loaded successfully!")
        return encoder
    
    except Exception as e:
        print(f"‚ùå Error loading encoder: {e}")
        print("Falling back to randomly initialized encoder...")
        
        # Fallback: initialize randomly (for testing)
        from surya.models.helio_spectformer import HelioSpectFormer
        encoder = HelioSpectFormer(
                    img_size=4096,
                    patch_size=16,
                    in_chans=13,
                    embed_dim=1280,
                    depth=10,
                    num_heads=16,
                    mlp_ratio=4.0,
                    dp_rank=1,
                    time_embedding={'type': 'linear', 'time_dim':1},
                    drop_rate = 0.1,
                    window_size=1,
                    n_spectral_blocks=1
                ).to(device)
        return encoder


# def load_surya_encoder(checkpoint_path: str, device: str = "cuda"):
#     """Load pre-trained Surya encoder from checkpoint."""
#     print(f"\nüß† Loading Surya encoder from {checkpoint_path}...")
    
#     try:
#         from workshop_infrastructure.models.finetune_models import HelioSpectformer2D
        
#         # 1. Initialize the Model (Random Weights)
#         model = HelioSpectformer2D(
#             img_size=4096,
#             patch_size=16,
#             in_chans=1,
#             embed_dim=1280,
#             time_embedding={'type': 'linear', 'time_dim': 1},
#             depth=10,
#             num_heads=16,
#             mlp_ratio=4.0,
#             drop_rate=0.1,
#             window_size=2,
#             dp_rank=1,
#             n_spectral_blocks=1,
#             config={} 
#         )
        
#         # 2. Load the Checkpoint File
#         # Use map_location='cpu' first to save GPU memory during processing
#         checkpoint = torch.load(checkpoint_path, map_location="cpu", weights_only=True)
        
#         # 3. Extract the State Dict
#         # Check if the checkpoint is wrapped (common in Lightning/Surya)
#         if "state_dict" in checkpoint:
#             state_dict = checkpoint["state_dict"]
#         elif "model" in checkpoint:
#             state_dict = checkpoint["model"]
#         else:
#             state_dict = checkpoint  # It might be the raw state dict
            
#         # 4. Filter and Fix Prefixes
#         model_state = model.state_dict()
#         filtered_state_dict = {}
#         loaded_keys_count = 0
        
#         for k, v in state_dict.items():
#             # Handle common prefix issues
#             clean_k = k.replace("model.", "").replace("encoder.", "").replace("_orig_mod.", "")
            
#             if clean_k in model_state:
#                 # Check shape compatibility
#                 if v.shape == model_state[clean_k].shape:
#                     filtered_state_dict[clean_k] = v
#                     loaded_keys_count += 1
#                 else:
#                     print(f"‚ö†Ô∏è Shape mismatch for {k}: Checkpoint {v.shape} vs Model {model_state[clean_k].shape}")
        
#         # 5. Sanity Check
#         if loaded_keys_count == 0:
#             raise RuntimeError("Checkpoint loaded but NO keys matched the model! (Check prefixes or file format)")
            
#         print(f"   Matches found: {loaded_keys_count}/{len(model_state)} layers.")

#         # 6. Load Weights
#         # We use strict=False because we might be loading a subset (encoder) into a larger model
#         model.load_state_dict(filtered_state_dict, strict=False)
        
#         encoder = model.to(device)
#         print("‚úÖ Surya encoder loaded successfully!")
#         return encoder
    
#     except Exception as e:
#         print(f"‚ùå Error loading encoder: {e}")
#         print("Falling back to randomly initialized encoder (WARNING: Results will be poor)...")
#         return model.to(device)

def create_wsa_model(
    encoder,
    encoder_out_channels: int = 1280,
    freeze_encoder: bool = True,
) -> WSAModel:
    """Create WSA model with encoder and decoder head."""
    print("\nüèóÔ∏è  Creating WSA model...")
    
    model = WSAModel(
        encoder=encoder,
        encoder_out_channels=encoder_out_channels,
        freeze_encoder=freeze_encoder,
    )
    
    freeze_status = "frozen" if freeze_encoder else "trainable"
    print(f"‚úÖ WSA model created (encoder: {freeze_status})")
    
    return model


# ============================================================================
# Metrics and Logging
# ============================================================================

def create_metrics():
    """Create metric calculators."""
    print("\nüìä Creating metrics...")
    
    train_loss_metrics = WSAMetrics("train_loss")
    train_eval_metrics = WSAMetrics("train_metrics")
    val_eval_metrics = WSAMetrics("val_metrics")
    
    print("‚úÖ Metrics created (MAE for train_loss, train_metrics, val_metrics)")
    
    return train_loss_metrics, train_eval_metrics, val_eval_metrics


def setup_loggers(config: dict) -> tuple:
    """Setup W&B and CSV loggers."""
    print("\nüìù Setting up loggers...")
    
    # Generate run name with timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_name = f"{config['wandb']['run_name']}_{timestamp}"
    
    # W&B Logger
    wandb_logger = WandbLogger(
        entity=config["wandb"]["entity"],
        project=config["wandb"]["project"],
        name=run_name,
        log_model=False,
        save_dir=os.environ.get("WANDB_DIR", "./wandb/wandb_tmp"),
    )
    
    # CSV Logger
    csv_logger = CSVLogger("runs", name="wsa_training")
    
    print(f"‚úÖ Loggers created:")
    print(f"   - W&B: {config['wandb']['project']} / {run_name}")
    print(f"   - CSV: runs/wsa_training/")
    
    return wandb_logger, csv_logger


# ============================================================================
# Training
# ============================================================================

def train(
    config: dict,
    train_loader,
    val_loader,
    model,
    metrics: dict,
    wandb_logger,
    csv_logger,
):
    """Execute training loop."""
    print("\nüöÄ Starting training...")
    
    # Create Lightning module
    lit_model = WSALightningModule(
        model=model,
        metrics=metrics,
        lr=config["optimizer"]["learning_rate"],
        batch_size=config["data"]["batch_size"],
    )
    
    # Create checkpoint directory
    checkpoint_dir = Path(config["checkpoint"]["save_dir"])
    checkpoint_dir.mkdir(parents=True, exist_ok=True)
    
    # Checkpoint callback
    checkpoint_callback = ModelCheckpoint(
        dirpath=checkpoint_dir,
        filename="wsa_best_{val_loss:.4f}",
        monitor=config["checkpoint"]["monitor"],
        mode=config["checkpoint"]["mode"],
        save_top_k=config["checkpoint"]["save_top_k"],
        verbose=True,
    )
    
    # Create trainer
    trainer = pl.Trainer(
        max_epochs=config["optimizer"]["max_epochs"],
        accelerator=config["device"],
        devices="auto",
        logger=[wandb_logger, csv_logger],
        callbacks=[checkpoint_callback],
        log_every_n_steps=config["logging"]["log_every_n_steps"],
        num_sanity_val_steps=0,  # Skip sanity check
        # --- ADD THIS ---
        gradient_clip_val=1.0,  # Clips gradients to max norm 1.0
        detect_anomaly=True     # Helps debug NaNs (slows down training, remove after fixing)
    )
    
    # Fit model
    trainer.fit(lit_model, train_loader, val_loader)
    
    print("\n‚úÖ Training completed!")
    print(f"üì¶ Best model saved to: {checkpoint_dir}/wsa_best_*.ckpt")
    
    return trainer, lit_model


# ============================================================================
# Main
# ============================================================================

def main():
    """Main training script."""
    print("=" * 80)
    print("WSA Map Prediction Training Script")
    print("=" * 80)
    
    # Parse arguments
    args = parse_args()
    
    # Setup environment
    setup_environment(args.cuda_device)
    
    # Load configuration
    config = load_config(args.config)
    
    # Build scalers
    scalers = build_scalers(info=config["data"]["scalers_path"])
    
    # Create datasets and dataloaders
    train_dataset, val_dataset, test_dataset = create_datasets(config, scalers)
    train_loader, val_loader, test_loader = create_dataloaders(
        train_dataset,
        val_dataset,
        test_dataset,
        batch_size=config["data"]["batch_size"],
        num_workers=config["data"]["num_data_workers"],
    )
    
    # Load pre-trained Surya encoder
    encoder = load_surya_encoder(config["model"]["checkpoint_path"])
    
    # Override freeze_encoder if CLI flag is set
    freeze_encoder = config["model"]["freeze_encoder"]
    if args.unfreeze_encoder:
        freeze_encoder = False
        print("üîì Encoder will be trainable (--unfreeze-encoder)")
    
    # Create WSA model
    wsa_model = create_wsa_model(
        encoder=encoder,
        encoder_out_channels=config["model"]["embed_dim"],
        freeze_encoder=freeze_encoder,
    )
    
    # Create metrics
    train_loss_metrics, train_eval_metrics, val_eval_metrics = create_metrics()
    metrics = {
        "train_loss": train_loss_metrics,
        "train_metrics": train_eval_metrics,
        "val_metrics": val_eval_metrics,
    }
    
    # Setup loggers
    wandb_logger, csv_logger = setup_loggers(config)
    
    # Train
    trainer, lit_model = train(
        config=config,
        train_loader=train_loader,
        val_loader=val_loader,
        model=wsa_model,
        metrics=metrics,
        wandb_logger=wandb_logger,
        csv_logger=csv_logger,
    )
    
    print("\n" + "=" * 80)
    print("Training Summary")
    print("=" * 80)
    print(f"Job ID: {config['job_id']}")
    print(f"Max Epochs: {config['optimizer']['max_epochs']}")
    print(f"Learning Rate: {config['optimizer']['learning_rate']}")
    print(f"Batch Size: {config['data']['batch_size']}")
    print(f"Encoder Frozen: {config['model']['freeze_encoder']}")
    print(f"Train CRs: {config['data']['train_crs']}")
    print(f"Val CRs: {config['data']['val_crs']}")
    print(f"Test CRs: {config['data']['test_crs']}")
    print("=" * 80 + "\n")


if __name__ == "__main__":
    main()